{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Data Handling and Preprocessing\n",
        "## Customer Feedback Analysis System\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\supra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\supra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\supra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\supra\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial dataset shape: (280, 7)\n",
            "\n",
            "Column names: ['Review Title', 'Customer name', 'Rating', 'Date', 'Category', 'Comments', 'Useful']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Customer name</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Date</th>\n",
              "      <th>Category</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Useful</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Another Midrange killer Smartphone by Xiaomi</td>\n",
              "      <td>Rishikumar Thakur</td>\n",
              "      <td>4.0 out of 5 stars</td>\n",
              "      <td>on 1 October 2018</td>\n",
              "      <td>Display</td>\n",
              "      <td>Another Midrange killer Smartphone by Xiaomi\\n...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vry small size mobile</td>\n",
              "      <td>Raza ji</td>\n",
              "      <td>3.0 out of 5 stars</td>\n",
              "      <td>on 15 September 2018</td>\n",
              "      <td>Others</td>\n",
              "      <td>All ok but vry small size mobile</td>\n",
              "      <td>7 people found this helpful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Full display not working in all application.</td>\n",
              "      <td>Vaibhav Patel</td>\n",
              "      <td>3.0 out of 5 stars</td>\n",
              "      <td>on 18 September 2018</td>\n",
              "      <td>Others</td>\n",
              "      <td>Quite good</td>\n",
              "      <td>7 people found this helpful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Value for Money</td>\n",
              "      <td>Amazon Customer</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>on 28 September 2018</td>\n",
              "      <td>Display</td>\n",
              "      <td>Redmi has always have been the the king of bud...</td>\n",
              "      <td>2 people found this helpful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Not worth for the money</td>\n",
              "      <td>Sudhakaran Wadakkancheri</td>\n",
              "      <td>2.0 out of 5 stars</td>\n",
              "      <td>on 18 September 2018</td>\n",
              "      <td>Others</td>\n",
              "      <td>worst product from MI. I am a hardcore fan of ...</td>\n",
              "      <td>6 people found this helpful</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Review Title             Customer name  \\\n",
              "0  Another Midrange killer Smartphone by Xiaomi         Rishikumar Thakur   \n",
              "1                         vry small size mobile                   Raza ji   \n",
              "2  Full display not working in all application.             Vaibhav Patel   \n",
              "3                               Value for Money           Amazon Customer   \n",
              "4                       Not worth for the money  Sudhakaran Wadakkancheri   \n",
              "\n",
              "               Rating                  Date Category  \\\n",
              "0  4.0 out of 5 stars     on 1 October 2018  Display   \n",
              "1  3.0 out of 5 stars  on 15 September 2018   Others   \n",
              "2  3.0 out of 5 stars  on 18 September 2018   Others   \n",
              "3  5.0 out of 5 stars  on 28 September 2018  Display   \n",
              "4  2.0 out of 5 stars  on 18 September 2018   Others   \n",
              "\n",
              "                                            Comments  \\\n",
              "0  Another Midrange killer Smartphone by Xiaomi\\n...   \n",
              "1                   All ok but vry small size mobile   \n",
              "2                                         Quite good   \n",
              "3  Redmi has always have been the the king of bud...   \n",
              "4  worst product from MI. I am a hardcore fan of ...   \n",
              "\n",
              "                        Useful  \n",
              "0                               \n",
              "1  7 people found this helpful  \n",
              "2  7 people found this helpful  \n",
              "3  2 people found this helpful  \n",
              "4  6 people found this helpful  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "try:\n",
        "    df = pd.read_csv('Customer_Feedback.csv', encoding='utf-8', on_bad_lines='skip')\n",
        "except:\n",
        "    try:\n",
        "        df = pd.read_csv('Customer_Feedback.csv', encoding='latin-1')\n",
        "    except:\n",
        "        df = pd.read_csv('Customer_Feedback.csv')\n",
        "\n",
        "print(f\"Initial dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values per column:\n",
            "Review Title       0\n",
            "Customer name      0\n",
            "Rating             0\n",
            "Date               0\n",
            "Category           0\n",
            "Comments           0\n",
            "Useful           170\n",
            "dtype: int64\n",
            "\n",
            "Data types:\n",
            "Review Title     object\n",
            "Customer name    object\n",
            "Rating           object\n",
            "Date             object\n",
            "Category         object\n",
            "Comments         object\n",
            "Useful           object\n",
            "dtype: object\n",
            "\n",
            "Duplicate rows: 21\n"
          ]
        }
      ],
      "source": [
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "print(f\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before removing duplicates: 280 rows\n",
            "After removing duplicates: 259 rows\n",
            "Removed 21 duplicate entries\n"
          ]
        }
      ],
      "source": [
        "df_clean = df.copy()\n",
        "\n",
        "print(f\"Before removing duplicates: {len(df_clean)} rows\")\n",
        "df_clean = df_clean.drop_duplicates()\n",
        "print(f\"After removing duplicates: {len(df_clean)} rows\")\n",
        "print(f\"Removed {len(df) - len(df_clean)} duplicate entries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values after filling:\n",
            "Review Title     0\n",
            "Customer name    0\n",
            "Rating           0\n",
            "Date             0\n",
            "Category         0\n",
            "Comments         0\n",
            "Useful           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df_clean['Comments'].fillna('', inplace=True)\n",
        "df_clean['Review Title'].fillna('', inplace=True)\n",
        "df_clean['Useful'].fillna('', inplace=True)\n",
        "\n",
        "print(\"Missing values after filling:\")\n",
        "print(df_clean.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_numeric_rating(rating_str):\n",
        "    if pd.isna(rating_str):\n",
        "        return np.nan\n",
        "    match = re.search(r'(\\d+\\.?\\d*)', str(rating_str))\n",
        "    return float(match.group(1)) if match else np.nan\n",
        "\n",
        "df_clean['Rating_Numeric'] = df_clean['Rating'].apply(extract_numeric_rating)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_date(date_str):\n",
        "    if pd.isna(date_str) or date_str == '':\n",
        "        return pd.NaT\n",
        "    try:\n",
        "        date_str = str(date_str).replace('on ', '')\n",
        "        return pd.to_datetime(date_str, format='%d %B %Y', errors='coerce')\n",
        "    except:\n",
        "        return pd.NaT\n",
        "\n",
        "df_clean['Date_Parsed'] = df_clean['Date'].apply(parse_date)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_helpful_count(useful_str):\n",
        "    if pd.isna(useful_str) or useful_str == '':\n",
        "        return 0\n",
        "    match = re.search(r'(\\d+)\\s*people?\\s*found\\s*this\\s*helpful', str(useful_str))\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    match = re.search(r'One\\s*person\\s*found\\s*this\\s*helpful', str(useful_str))\n",
        "    if match:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "df_clean['Helpful_Count'] = df_clean['Useful'].apply(extract_helpful_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Preprocessing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if pd.isna(text) or text == '':\n",
        "        return ''\n",
        "    \n",
        "    text = str(text)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s.,!?]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "    if not text or text == '':\n",
        "        return []\n",
        "    try:\n",
        "        tokens = word_tokenize(text.lower())\n",
        "        return tokens\n",
        "    except:\n",
        "        return text.lower().split()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_stopwords(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
        "    return filtered_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lemmatize_tokens(tokens):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return lemmatized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_pipeline(text):\n",
        "    cleaned = clean_text(text)\n",
        "    tokens = tokenize_text(cleaned)\n",
        "    filtered = remove_stopwords(tokens)\n",
        "    lemmatized = lemmatize_tokens(filtered)\n",
        "    return ' '.join(lemmatized)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Preprocessing to Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing review titles...\n",
            "Preprocessing comments...\n",
            "Preprocessing completed!\n"
          ]
        }
      ],
      "source": [
        "print(\"Preprocessing review titles...\")\n",
        "df_clean['Review_Title_Clean'] = df_clean['Review Title'].apply(clean_text)\n",
        "df_clean['Review_Title_Processed'] = df_clean['Review Title'].apply(preprocess_pipeline)\n",
        "\n",
        "print(\"Preprocessing comments...\")\n",
        "df_clean['Comments_Clean'] = df_clean['Comments'].apply(clean_text)\n",
        "df_clean['Comments_Processed'] = df_clean['Comments'].apply(preprocess_pipeline)\n",
        "\n",
        "print(\"Preprocessing completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean['Combined_Text'] = df_clean['Review_Title_Clean'] + ' ' + df_clean['Comments_Clean']\n",
        "df_clean['Combined_Text_Processed'] = df_clean['Review_Title_Processed'] + ' ' + df_clean['Comments_Processed']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean['Text_Length'] = df_clean['Combined_Text'].apply(len)\n",
        "df_clean['Word_Count'] = df_clean['Combined_Text'].apply(lambda x: len(x.split()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Data Quality Checks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset shape: (259, 18)\n",
            "\n",
            "Columns in cleaned dataset:\n",
            "['Review Title', 'Customer name', 'Rating', 'Date', 'Category', 'Comments', 'Useful', 'Rating_Numeric', 'Date_Parsed', 'Helpful_Count', 'Review_Title_Clean', 'Review_Title_Processed', 'Comments_Clean', 'Comments_Processed', 'Combined_Text', 'Combined_Text_Processed', 'Text_Length', 'Word_Count']\n",
            "\n",
            "Missing values:\n",
            "Review Title               0\n",
            "Customer name              0\n",
            "Rating                     0\n",
            "Date                       0\n",
            "Category                   0\n",
            "Comments                   0\n",
            "Useful                     0\n",
            "Rating_Numeric             0\n",
            "Date_Parsed                0\n",
            "Helpful_Count              0\n",
            "Review_Title_Clean         0\n",
            "Review_Title_Processed     0\n",
            "Comments_Clean             0\n",
            "Comments_Processed         0\n",
            "Combined_Text              0\n",
            "Combined_Text_Processed    0\n",
            "Text_Length                0\n",
            "Word_Count                 0\n",
            "dtype: int64\n",
            "\n",
            "Rating distribution:\n",
            "Rating_Numeric\n",
            "1.0     42\n",
            "2.0      6\n",
            "3.0     23\n",
            "4.0     44\n",
            "5.0    144\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f\"Final dataset shape: {df_clean.shape}\")\n",
        "print(f\"\\nColumns in cleaned dataset:\")\n",
        "print(df_clean.columns.tolist())\n",
        "print(f\"\\nMissing values:\")\n",
        "print(df_clean.isnull().sum())\n",
        "print(f\"\\nRating distribution:\")\n",
        "print(df_clean['Rating_Numeric'].value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample of cleaned data:\n",
            "\n",
            "Original Comment:\n",
            "Another Midrange killer Smartphone by Xiaomi\n",
            "\n",
            "Major Highlights:\n",
            " The Redmi 6 Pro sports a 5.84-inch full-HD+ display with a notch\n",
            " Powered by the Qualcomm Snapdragon 625 SoC\n",
            " The phone is priced at\n",
            "\n",
            "Cleaned Comment:\n",
            "Another Midrange killer Smartphone by Xiaomi Major Highlights The Redmi 6 Pro sports a 5.84 inch full HD display with a notch Powered by the Qualcomm Snapdragon 625 SoC The phone is priced at Rs. 10,9\n",
            "\n",
            "Processed Comment:\n",
            "another midrange killer smartphone xiaomi major highlight redmi pro sport 5.84 inch full display notch powered qualcomm snapdragon 625 soc phone priced 10,999 3gb ram variant start point battery 4000 \n"
          ]
        }
      ],
      "source": [
        "print(\"Sample of cleaned data:\")\n",
        "print(\"\\nOriginal Comment:\")\n",
        "print(df_clean.iloc[0]['Comments'][:200])\n",
        "print(\"\\nCleaned Comment:\")\n",
        "print(df_clean.iloc[0]['Comments_Clean'][:200])\n",
        "print(\"\\nProcessed Comment:\")\n",
        "print(df_clean.iloc[0]['Comments_Processed'][:200])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cleaned dataset saved as 'cleaned_customer_feedback.csv'\n",
            "Total records: 259\n"
          ]
        }
      ],
      "source": [
        "df_final = df_clean[[\n",
        "    'Review Title', 'Customer name', 'Rating', 'Rating_Numeric',\n",
        "    'Date', 'Date_Parsed', 'Category', 'Comments', 'Useful', 'Helpful_Count',\n",
        "    'Review_Title_Clean', 'Comments_Clean', 'Combined_Text',\n",
        "    'Review_Title_Processed', 'Comments_Processed', 'Combined_Text_Processed',\n",
        "    'Text_Length', 'Word_Count'\n",
        "]]\n",
        "\n",
        "df_final.to_csv('cleaned_customer_feedback.csv', index=False)\n",
        "print(\"\\nCleaned dataset saved as 'cleaned_customer_feedback.csv'\")\n",
        "print(f\"Total records: {len(df_final)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DATA PREPROCESSING SUMMARY\n",
            "============================================================\n",
            "\n",
            "Original dataset size: 280 records\n",
            "Cleaned dataset size: 259 records\n",
            "Records removed: 21\n",
            "\n",
            "Rating Statistics:\n",
            "count    259.000000\n",
            "mean       3.934363\n",
            "std        1.483611\n",
            "min        1.000000\n",
            "25%        3.000000\n",
            "50%        5.000000\n",
            "75%        5.000000\n",
            "max        5.000000\n",
            "Name: Rating_Numeric, dtype: float64\n",
            "\n",
            "Category Distribution:\n",
            "Category\n",
            "Others      168\n",
            "Display      32\n",
            "Battery      27\n",
            "Camera       26\n",
            "Delivery      6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Text Length Statistics:\n",
            "count     259.000000\n",
            "mean      152.926641\n",
            "std       401.347573\n",
            "min         5.000000\n",
            "25%        22.000000\n",
            "50%        50.000000\n",
            "75%       117.500000\n",
            "max      4579.000000\n",
            "Name: Text_Length, dtype: float64\n",
            "\n",
            "Word Count Statistics:\n",
            "count    259.000000\n",
            "mean      28.146718\n",
            "std       75.911883\n",
            "min        2.000000\n",
            "25%        4.000000\n",
            "50%        9.000000\n",
            "75%       21.500000\n",
            "max      860.000000\n",
            "Name: Word_Count, dtype: float64\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"DATA PREPROCESSING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nOriginal dataset size: {len(df)} records\")\n",
        "print(f\"Cleaned dataset size: {len(df_final)} records\")\n",
        "print(f\"Records removed: {len(df) - len(df_final)}\")\n",
        "print(f\"\\nRating Statistics:\")\n",
        "print(df_final['Rating_Numeric'].describe())\n",
        "print(f\"\\nCategory Distribution:\")\n",
        "print(df_final['Category'].value_counts())\n",
        "print(f\"\\nText Length Statistics:\")\n",
        "print(df_final['Text_Length'].describe())\n",
        "print(f\"\\nWord Count Statistics:\")\n",
        "print(df_final['Word_Count'].describe())\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
